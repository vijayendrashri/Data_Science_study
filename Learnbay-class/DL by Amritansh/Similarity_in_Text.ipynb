{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Similarity in Text.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdIXY4tcxtwM"
      },
      "source": [
        "# String Similarity\n",
        "\n",
        "For example,\n",
        "\n",
        "Given string A: \"Robert\",\n",
        "\n",
        "Then string B: \"Amy Robertson\"\n",
        "\n",
        "would be a better match than String C: \"Richard\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfnQKT7fuMmJ"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/1190/0*gyYGdraryZl76Akx.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSY0KIvk_7ys"
      },
      "source": [
        "### Using simple sequence matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzjEI5bQxp3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06507be-ab8b-402d-e85e-970aa3a98bd0"
      },
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def similar(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "similar(\"brown\",\"beer\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4444444444444444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxQs1F8RW-Ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a09185f-0e73-4da2-d059-b51c373b1ae8"
      },
      "source": [
        "# similar(\"Apple\", \"apple\")\n",
        "similar(\"apple\",\"mango\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQm9wxdRwMkG",
        "outputId": "91487aa9-a925-4b23-e71e-8780ae1921f1"
      },
      "source": [
        "similar(\"good\",\"better\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9viQdQDb-RY"
      },
      "source": [
        "### Cosine Similarity\n",
        "\n",
        "\n",
        "Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. The cosine of 0° is 1, and it is less than 1 for any angle in the interval (0,π] radians. It is thus a judgment of orientation and not magnitude: two vectors with the same orientation have a cosine similarity of 1, two vectors oriented at 90° relative to each other have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj-GS-g9cImi"
      },
      "source": [
        "![alt text](https://i2.wp.com/dataaspirant.com/wp-content/uploads/2015/04/cosine.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obXD9DrpdBZ5"
      },
      "source": [
        "![alt text](https://neo4j.com/docs/graph-algorithms/current/images/cosine-similarity.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fK7nbwCdUCh"
      },
      "source": [
        "![alt text](https://datascience-enthusiast.com/figures/cosine_sim.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNSUrJgZb93f"
      },
      "source": [
        "# dummy code\n",
        "def cosine_similarity(u, v):\n",
        "    \"\"\"\n",
        "    Cosine similarity reflects the degree of similariy between u and v\n",
        "        \n",
        "    Arguments:\n",
        "        u -- a word vector of shape (n,)          \n",
        "        v -- a word vector of shape (n,)\n",
        "\n",
        "    Returns:\n",
        "        cosine_similarity -- the cosine similarity between u and v defined by the formula above.\n",
        "    \"\"\"\n",
        "    \n",
        "    distance = 0.0\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Compute the dot product between u and v (≈1 line)\n",
        "    dot = np.dot(u, v)\n",
        "    # Compute the L2 norm of u (≈1 line)\n",
        "    norm_u = np.sqrt(np.sum(u**2))\n",
        "    \n",
        "    # Compute the L2 norm of v (≈1 line)\n",
        "    norm_v = np.sqrt(np.sum(v**2))\n",
        "    # Compute the cosine similarity defined by formula (1) (≈1 line)\n",
        "    cosine_similarity = dot / np.dot(norm_u, norm_v)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3UHAT5deAjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92f370d-ab6e-4895-95b6-78279f90eb12"
      },
      "source": [
        "import re, math\n",
        "from collections import Counter\n",
        "\n",
        "WORD = re.compile(r'\\w+')\n",
        "\n",
        "def get_cosine(vec1, vec2):\n",
        "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "     if not denominator:\n",
        "        return 0.0\n",
        "     else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "def text_to_vector(text):\n",
        "     words = WORD.findall(text)\n",
        "     return Counter(words)\n",
        "\n",
        "s1 = \"This is a foo bar sentence .\"\n",
        "s2 = \"This sentence is similar to a foo bar sentence .\"\n",
        "s3 = \"What is this string ? Totally not related to the other two lines .\"\n",
        "\n",
        "vector1 = text_to_vector(s1)\n",
        "print(vector1)\n",
        "vector2 = text_to_vector(s2)\n",
        "vector3 = text_to_vector(s3)\n",
        "cosine1 = get_cosine(vector1, vector2)\n",
        "cosine2 = get_cosine(vector2, vector3)\n",
        "print ('Cosine_01:', cosine1)\n",
        "print ('Cosine_02:', cosine2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'This': 1, 'is': 1, 'a': 1, 'foo': 1, 'bar': 1, 'sentence': 1})\n",
            "Cosine_01: 0.8616404368553293\n",
            "Cosine_02: 0.17407765595569785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjUdqOvrCLqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43561503-c63c-4bca-eb9b-041765218242"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_distances,cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "dog = np.asarray([[1.2, 0.9, 1.45]])\n",
        "cat = np.asarray([[1.1, 0.1, 1.1 ]])\n",
        "mouse = np.asarray([[0.1, -0.9, 0.01]])\n",
        "\n",
        "print (cosine_similarity(dog,mouse))\n",
        "print (cosine_similarity(dog,cat))\n",
        "print (cosine_distances(dog,mouse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.35753829]]\n",
            "[[0.92399995]]\n",
            "[[1.35753829]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13rVKYfSPp_N"
      },
      "source": [
        "### Levenshtein distance\n",
        "In information theory, linguistics and computer science, the Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other. It is named after the Soviet mathematician Vladimir Levenshtein, who considered this distance in 1965\n",
        "\n",
        "The greater the Levenshtein distance, the greater are the difference between the strings. For example, from \"test\" to \"test\" the Levenshtein distance is 0 because both the source and target strings are identical. No transformations are needed. In contrast, from \"test\" to \"team\" the Levenshtein distance is 2 - two substitutions have to be done to turn \"test\" in to \"team\".\n",
        "\n",
        "The Levenshtein Distance and the underlying ideas are widely used in areas like computer science, computer linguistics, and even bioinformatics, molecular biology, DNA analysis. You can even measure the similarity of melodies or rhythms in music"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95R6DZsp4KpX"
      },
      "source": [
        "cities = {\"Pittsburgh\":\"Pennsylvania\",\n",
        "          \"Tucson\":\"Arizona\",\n",
        "          \"Cincinnati\":\"Ohio\",\n",
        "          \"Albuquerque\":\"New Mexico\",\n",
        "          \"Culpeper\":\"Virginia\",\n",
        "          \"Asheville\":\"North Carolina\",\n",
        "          \"Worcester\":\"Massachusetts\",\n",
        "          \"Manhattan\":\"New York\",\n",
        "          \"Phoenix\":\"Arizona\",\n",
        "          \"Niagara Falls\":\"New York\"} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "ENWgQGkOkb1q",
        "outputId": "4a95fbce-1327-421b-8730-22543b9dbf68"
      },
      "source": [
        "cities[\"Tuscon\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-fd39464eb7f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Tuscon\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'Tuscon'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbEEOt7vikCG"
      },
      "source": [
        "So, trying to get the corresponding state names via the following dictionary accesses will raise exceptions:\n",
        "\n",
        "cities[\"Tuscon\"]\n",
        "\n",
        " cities[\"Pittsburg\"] \n",
        " \n",
        " cities[\"Cincinati\"] \n",
        " \n",
        " cities[\"Albequerque\"]\n",
        "\n",
        "If a human reader looks at these misspellings, he or she will have no problem in recognizing the city you have in mind. The Python dictionary on the other hand is pedantic and unforgivable. It only accepts a key, if it is exactly identical.\n",
        "\n",
        "The question is to what degree are two strings similar? What we need is a string similarity metric or a measure for the \"distance\" of strings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQj7FTir4jv2"
      },
      "source": [
        "The minimum edit distance between two strings is the minimum numer of editing operations needed to convert one string into another. The editing operations can consist of insertions, deletions and substitutions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arMWPABP4lEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc95c332-c4e6-4fde-87a3-ec231c8e003e"
      },
      "source": [
        "# Insertion of a single symbol. This means that we add a character to a string s. \n",
        "# Example: If we have the string s = \"Manhatan\", we can insert the character \"t\" to get the correct spelling\n",
        "\n",
        "s = \"Manhatan\"\n",
        "s = s[:5] + \"t\" + s[5:]\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Manhattan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HFapgxK4621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dbc81d62-fb8e-4b7d-8a18-a3a2746395bf"
      },
      "source": [
        "# Deletion of a single symbol\n",
        "\n",
        "s = \"Mannhattan\"\n",
        "s = s[:2] + s[3:]\n",
        "s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Manhattan'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxMU-ikL5ESm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "154d5fbc-266c-448d-84bb-1ecebc591b7e"
      },
      "source": [
        "# Substitution of a single symbol In the following example, we have to change the letter \"o\" into the letter \"a\" to get the correct spelling\n",
        "\n",
        "s = \"Manhatton\"\n",
        "s = s[:7] + \"a\" + s[8:]\n",
        "s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Manhattan'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH-Jvc0e5NjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53492a7-e2f7-4edd-cda0-2a380c89e12f"
      },
      "source": [
        "\"\"\"\n",
        "The minimum edit distance between the two strings \"Mannhaton\" and \"Manhattan\" \n",
        "corresponds to the value 3, as we need three basic editing operation to transform\n",
        "the first one into the second one\n",
        "\"\"\"\n",
        "s = \"Mannhaton\"\n",
        "s = s[:2] + s[3:]         # deletion\n",
        "print(s)\n",
        "\n",
        "s = s[:5] + \"t\" + s[5:]   # insertion\n",
        "print(s)\n",
        "\n",
        "s = s[:7] + \"a\" + s[8:]   # substitution\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Manhaton\n",
            "Manhatton\n",
            "Manhattan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOWSbO0X6IH9"
      },
      "source": [
        "The Levenshtein distance between two strings a and b is given by leva,b(len(a), len(b)) where leva,b(i, j) is equal to\n",
        "\n",
        "![alt text](http://www.cuelogic.com/wp-content/uploads/2017/01/Maths.jpg)\n",
        "\n",
        "\n",
        "The Levenshtein distance has the following properties:\n",
        "\n",
        "* It is zero if and only if the strings are equal.\n",
        "* It is at least the difference of the sizes of the two strings.\n",
        "* It is at most the length of the longer string.\n",
        "* Triangle inequality: The Levenshtein distance between two strings is no greater than the sum of their Levenshtein distances from a third string.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqV9vtui65Hu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10092332-849f-46f1-c847-670a48604c8b"
      },
      "source": [
        "# recursive implementation of LD\n",
        "def LD(s, t):\n",
        "    if s == \"\":\n",
        "        return len(t)\n",
        "    if t == \"\":\n",
        "        return len(s)\n",
        "    if s[-1] == t[-1]:\n",
        "        cost = 0\n",
        "    else:\n",
        "        cost = 1\n",
        "       \n",
        "    res = min([LD(s[:-1], t)+1,\n",
        "               LD(s, t[:-1])+1, \n",
        "               LD(s[:-1], t[:-1]) + cost])\n",
        "    return res\n",
        "print(LD(\"Python\", \"Peithen\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl9UnJum7vvK"
      },
      "source": [
        "This recursive implementation is very inefficient because it recomputes the Levenshtein distance of the same substrings over and over again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_vfpZT27umU"
      },
      "source": [
        "To compute the Levenshtein distance in a non-recursive way, we use a matrix containing the Levenshtein distances between all prefixes of the first string and all prefixes of the second one. We can dynamically compute the values in this matrix. The last value computed will be the distance between the two full strings. This is an algorithmic example of a bottom-up dynamic programming.\n",
        "\n",
        "The algorithm works like this:\n",
        "We set the cost for an insertion, a deletion and a substitution to 1. We want to calculate the distance between two string s and t with len(s) == m and len(t) == n. A matrix D is used, which contains in the (i,j)-cell the Levenshtein distance between s[:i+1] and t[:j+1]. The values of the matrix will be calculated starting with the upper left corner and ending with the lower right corner.\n",
        "\n",
        "We start with filling in the base cases, i.e. the row and the column with the index 0. Calculation in this case means that we fill the row with index 0 with the lenghts of the substrings of t and respectively fill the column with the index 0 with the lengths of the substrings of s.\n",
        "\n",
        "The values of all the other elements of the matrix only depend on the values of their left neighbour, the top neightbour and the top left one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arWrQKND7JNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6694e8b-16e9-4ffa-8bcf-7b5df087a469"
      },
      "source": [
        "def iterative_levenshtein(s, t):\n",
        "    \"\"\" \n",
        "        iterative_levenshtein(s, t) -> ldist\n",
        "        ldist is the Levenshtein distance between the strings \n",
        "        s and t.\n",
        "        For all i and j, dist[i,j] will contain the Levenshtein \n",
        "        distance between the first i characters of s and the \n",
        "        first j characters of t\n",
        "    \"\"\"\n",
        "    rows = len(s)+1\n",
        "    cols = len(t)+1\n",
        "    dist = [[0 for x in range(cols)] for x in range(rows)]\n",
        "    # source prefixes can be transformed into empty strings \n",
        "    # by deletions:\n",
        "    for i in range(1, rows):\n",
        "        dist[i][0] = i\n",
        "    # target prefixes can be created from an empty source string\n",
        "    # by inserting the characters\n",
        "    for i in range(1, cols):\n",
        "        dist[0][i] = i\n",
        "        \n",
        "    for col in range(1, cols):\n",
        "        for row in range(1, rows):\n",
        "            if s[row-1] == t[col-1]:\n",
        "                cost = 0\n",
        "            else:\n",
        "                cost = 1\n",
        "            dist[row][col] = min(dist[row-1][col] + 1,      # deletion\n",
        "                                 dist[row][col-1] + 1,      # insertion\n",
        "                                 dist[row-1][col-1] + cost) # substitution\n",
        "    for r in range(rows):\n",
        "        print(dist[r])\n",
        "    \n",
        " \n",
        "    return dist[row][col]\n",
        "print(iterative_levenshtein(\"flaw\", \"lawn\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4]\n",
            "[1, 1, 2, 3, 4]\n",
            "[2, 1, 2, 3, 4]\n",
            "[3, 2, 1, 2, 3]\n",
            "[4, 3, 2, 1, 2]\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZMJHBc_8BNd"
      },
      "source": [
        "![alt text](https://www.python-course.eu/images/levenshtein_distance_matrix_explained.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY15ftt67Zf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2262b73-5a15-480d-a824-ab9364723026"
      },
      "source": [
        "print(iterative_levenshtein(\"Manhattan\", \"Manahaton\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[1, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "[2, 1, 0, 1, 2, 3, 4, 5, 6, 7]\n",
            "[3, 2, 1, 0, 1, 2, 3, 4, 5, 6]\n",
            "[4, 3, 2, 1, 1, 1, 2, 3, 4, 5]\n",
            "[5, 4, 3, 2, 1, 2, 1, 2, 3, 4]\n",
            "[6, 5, 4, 3, 2, 2, 2, 1, 2, 3]\n",
            "[7, 6, 5, 4, 3, 3, 3, 2, 2, 3]\n",
            "[8, 7, 6, 5, 4, 4, 3, 3, 3, 3]\n",
            "[9, 8, 7, 6, 5, 5, 4, 4, 4, 3]\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDcBOkLdMExc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573aed6b-630d-454b-cc01-60b9af1b73b9"
      },
      "source": [
        "! pip install python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
            "\r\u001b[K     |██████▌                         | 10kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (56.1.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149802 sha256=22d687006ce4bf2ec790e45559aabce567f9c4ab3bbc11c41536a0f128e9ba1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDPoLczua2p1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08397cdc-6099-44fe-9a49-ec1f4382a1ca"
      },
      "source": [
        "import Levenshtein\n",
        "\n",
        "\"\"\"\n",
        "distance(string1, string2)\n",
        "Compute absolute Levenshtein distance of two strings\n",
        "\n",
        "\"\"\"\n",
        "Levenshtein.distance(\"Exxon\", \"Exam\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNsqDDPBin--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "983366bd-20b4-4136-c817-df4978efed7f"
      },
      "source": [
        "Levenshtein.distance('Levenshtein', 'Lenvinsten')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx3lAJWhi4CG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "220ec2ba-44af-47af-91da-ca41b182a2b4"
      },
      "source": [
        "# median function\n",
        "\"\"\"\n",
        "median(string_sequence[, weight_sequence])\n",
        "Find an approximate generalized median string using greedy algorithm.\n",
        "\n",
        "You can optionally pass a weight for each string as the second argument. \n",
        "The weights are interpreted as item multiplicities, \n",
        "although any non-negative real numbers are accepted. \n",
        "Use them to improve computation speed when strings often appear multiple times in the sequence.\n",
        "\"\"\"\n",
        "Levenshtein.median(['SpSm', 'mpamm', 'Spam', 'Spa', 'Sua', 'hSam'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Spam'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vn6GWN1jJX_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "14687160-5542-4ca2-d57d-8bc7ae4a0ae0"
      },
      "source": [
        "fixme = ['Levnhtein', 'Leveshein', 'Leenshten',\n",
        "...          'Leveshtei', 'Lenshtein', 'Lvenstein',\n",
        "...          'Levenhtin', 'evenshtei']\n",
        "Levenshtein.median(fixme)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Levenshtein'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tPpZJrToo8AF",
        "outputId": "561e0984-8a9d-46aa-ef82-ab63413718e1"
      },
      "source": [
        "# fixme = [\"beer\", \"bear\",\"beare\",\"beere\",\"beeri\",\"beire\", \"beer\"]\n",
        "fixme = [\"beer\", \"bear\",\"beire\",\"beere\",\"beer\",\"beire\", \"bee\"]\n",
        "Levenshtein.median(fixme)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'beer'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gXy08oUA5aY"
      },
      "source": [
        "The Levenshtein distance algorithm has been used in:\n",
        "\n",
        "* Spell checking\n",
        "* Speech recognition\n",
        "* DNA analysis\n",
        "* Plagiarism detection\n",
        "\n",
        "amongst other applications."
      ]
    }
  ]
}
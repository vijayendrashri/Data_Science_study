{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Import libraries we'll need\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "#visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e2d149fb0508a92a3777c45ef8bbc41e7b929c1a"
   },
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1984572a2aaf969d40af01508c470b6b80465fb3"
   },
   "source": [
    "# Understand & clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bad4fde79b34960996bdbe15827bb9d4aff91a09"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d18328ff2e2ecaef8483bb84357cbc082f8d5a4"
   },
   "source": [
    "View the unique data by column. There are a few columns we can convert to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "10342cdbf7d96670a01c00608226ee3187c3b734"
   },
   "outputs": [],
   "source": [
    "for item in df.columns:\n",
    "    print(item)\n",
    "    print (df[item].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ebbe730ef9b9418a76ff51339429c83ce7d7ba7d"
   },
   "source": [
    "Let's convert strings to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e788256a7a56644ee240e89b4d677633fe91e9b2"
   },
   "outputs": [],
   "source": [
    "for item in df.columns:\n",
    "    try:\n",
    "        df[item] = df[item].str.lower()\n",
    "    except:\n",
    "        print(item, \"couldn't convert\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f1947d524368ec97073de6dc9c397ce24ef35d94"
   },
   "source": [
    "Convert all yes and no to 0's & 1's so our classifier can use this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec8e947a7feee183f3b98cb1269a829c40815751"
   },
   "outputs": [],
   "source": [
    "columns_to_convert = ['Partner', \n",
    "                      'Dependents', \n",
    "                      'PhoneService', \n",
    "                      'PaperlessBilling', \n",
    "                      'Churn']\n",
    "\n",
    "for item in columns_to_convert:\n",
    "    df[item].replace(to_replace='yes', value=1, inplace=True)\n",
    "    df[item].replace(to_replace='no',  value=0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75e1773c0d4081a96e5a88809cd9ac0208870b01"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e38c5c55b9978501bb59fe3ce5696b91f057edc"
   },
   "source": [
    "We can see TotalCharges is still an object. Fix TotalCharges as a float..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8715ef563adda5741f95ae31f8c1035ae0e6e447"
   },
   "outputs": [],
   "source": [
    "df['TotalCharges'] = df['TotalCharges'].replace(r'\\s+', np.nan, regex=True)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c66ce2ce47ec851c14f513ca7a2cb6f63573369"
   },
   "source": [
    "Check for NULLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d190a086547fd2243fd23a3920689455bcb994cb"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cd51e23379d9c2b096e772ef3daaee3c3aa46fc"
   },
   "outputs": [],
   "source": [
    "df = df.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b91db44074b85bafb806c7aaba8e145ae55a31a"
   },
   "source": [
    "Balance the labels so we have the same number of non-churners as churners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e6ff1048af9cb40a9585e8d0eee2920bcbe3cc3"
   },
   "outputs": [],
   "source": [
    "churners_number = len(df[df['Churn'] == 1])\n",
    "print(\"Number of churners\", churners_number)\n",
    "\n",
    "churners = (df[df['Churn'] == 1])\n",
    "\n",
    "non_churners = df[df['Churn'] == 0].sample(n=churners_number)\n",
    "print(\"Number of non-churners\", len(non_churners))\n",
    "df2 = churners.append(non_churners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e1218f9ca1ba189d0d1525f5a54bdcc37c032cd"
   },
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e6171ebc676396183d2444f4564b24081174964f"
   },
   "source": [
    "Are there any strong correlations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e634d5f8921b0aa2543de179882a6be1416d9c2"
   },
   "outputs": [],
   "source": [
    "def show_correlations(dataframe, show_chart = True):\n",
    "    fig = plt.figure(figsize = (20,10))\n",
    "    corr = dataframe.corr()\n",
    "    if show_chart == True:\n",
    "        sns.heatmap(corr, \n",
    "                    xticklabels=corr.columns.values,\n",
    "                    yticklabels=corr.columns.values,\n",
    "                    annot=True)\n",
    "    return corr\n",
    "\n",
    "correlation_df = show_correlations(df2,show_chart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca39f31b83fbc7d3c85a06316c2546705ff04e2f"
   },
   "source": [
    "Let's now build a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b273f022ef6661ab75acd27665e35ad9816f1387"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    customer_id = df2['customerID'] # Store this as customer_id variable\n",
    "    del df2['customerID'] # Don't need in ML DF\n",
    "except:\n",
    "    print(\"already removed customerID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56190336afe379d9cee52218c4a7810b73f208a3"
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21fdb784b59d3e1999e9e7ea920a543b0735d52a"
   },
   "source": [
    "Use one-hot encoding to convert categorical data to binary (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3fad12f11036a51f26f29662328b0f79d78f7d44"
   },
   "outputs": [],
   "source": [
    "ml_dummies = pd.get_dummies(df2)\n",
    "ml_dummies.fillna(value=0, inplace=True)\n",
    "ml_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ae45bb99b3ffbf865f607f70493d51f0ff20a8a"
   },
   "outputs": [],
   "source": [
    "# Add a random column to the dataframe\n",
    "ml_dummies['---randomColumn---'] = np.random.randint(0,1000, size=len(ml_dummies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e44f7ae80ec83cddce9f6c912270e7d3362ac83"
   },
   "outputs": [],
   "source": [
    "show_correlations(ml_dummies, show_chart=False)[\"Churn\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8260a93932a14bbed2c8b4740dae6e94a4dfae06"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    label = ml_dummies['Churn'] # Remove the label before training the model\n",
    "    del ml_dummies['Churn']\n",
    "except:\n",
    "    print(\"label already removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "167ff9b5bee53675949a0e7801acbab72b42a53f"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_train, feature_test, label_train, label_test = train_test_split(ml_dummies, label, test_size=0.3)\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),    \n",
    "    DecisionTreeClassifier(max_depth=5)\n",
    "]\n",
    "    \n",
    "\n",
    "# iterate over classifiers\n",
    "for item in classifiers:\n",
    "    classifier_name = ((str(item)[:(str(item).find(\"(\"))]))\n",
    "    print (classifier_name)\n",
    "    \n",
    "    # Create classifier, train it and test it.\n",
    "    clf = item\n",
    "    clf.fit(feature_train, label_train)\n",
    "    pred = clf.predict(feature_test)\n",
    "    score = clf.score(feature_test, label_test)\n",
    "    print (round(score,3),\"\\n\", \"- - - - - \", \"\\n\")\n",
    "    \n",
    "feature_df = pd.DataFrame()\n",
    "feature_df['features'] = ml_dummies.columns\n",
    "feature_df['importance'] = clf.feature_importances_\n",
    "feature_df.sort_values(by='importance', ascending=False)    \n",
    "feature_df.set_index(keys='features').sort_values(by='importance', ascending=True).plot(kind='barh', figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09b78d1a7f2aaf414cd758802fce12b3b69c88f6"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(label_test, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "class_names = ['Not churned','churned']\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "eval_metrics = classification_report(label_test, pred, target_names=class_names)\n",
    "print(eval_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4e58e5ff2a35dab6d38767e02abd61aca2b0edc1"
   },
   "source": [
    "This result seems conservative. We're more likely to say someone is going to churn when they're not vs predicting someone's not going to churn when they do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ac0f2adf8a4be8c78108fcbee55f075d5451e39"
   },
   "source": [
    "# Grid Search to tweak parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f043eb14e1d665219b3b7aa7428d820bffda18f0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "max_depth_range = range(2,20,2)\n",
    "leaf_range = range(1,10,2)\n",
    "n_estimators_range = range(10,200,10)\n",
    "max_features_range = range(1,len(ml_dummies.columns),5)\n",
    "\n",
    "\n",
    "param_grid = dict(max_depth = max_depth_range,\n",
    "                 min_samples_leaf = leaf_range,\n",
    "                 n_estimators = n_estimators_range,\n",
    "                 max_features = max_features_range\n",
    "                )\n",
    "\n",
    "### Warning, can take some time\n",
    "\n",
    "# d_tree = RandomForestClassifier()\n",
    "# grid = GridSearchCV(d_tree, param_grid, cv=5, scoring = 'accuracy', verbose=1, return_train_score=True)\n",
    "# grid.fit(feature_train, label_train)\n",
    "# print (grid.best_score_)\n",
    "# print (grid.best_params_)\n",
    "# print (grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6049a52b4a06a1a276afaffb4532f5315583aee9"
   },
   "source": [
    "# Make predictions on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ad77b7dcda408f34969190c3f957ea8d483c366"
   },
   "outputs": [],
   "source": [
    "# Preprocessing original dataframe\n",
    "def preprocess_df(dataframe):\n",
    "    x = dataframe.copy()\n",
    "    try:\n",
    "        customer_id = x['customerID']\n",
    "        del x['customerID'] # Don't need in ML DF\n",
    "    except:\n",
    "        print(\"already removed customerID\")\n",
    "    ml_dummies = pd.get_dummies(x)\n",
    "    ml_dummies.fillna(value=0, inplace=True)\n",
    "\n",
    "    # import random done above\n",
    "    ml_dummies['---randomColumn---'] = np.random.randint(0,1000, size=len(ml_dummies))\n",
    "\n",
    "    try:\n",
    "        label = ml_dummies['Churn']\n",
    "        del ml_dummies['Churn']\n",
    "    except:\n",
    "        print(\"label already removed.\")\n",
    "    return ml_dummies, customer_id, label\n",
    "\n",
    "original_df = preprocess_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b11632fcdfee87db9f3a0fdc345d073ee739e587"
   },
   "outputs": [],
   "source": [
    "output_df = original_df[0].copy()\n",
    "output_df['---randomColumn---']\n",
    "output_df['prediction'] = clf.predict_proba(output_df)[:,1]\n",
    "output_df['churn'] = original_df[2]\n",
    "output_df['customerID'] = original_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1bf5a3e6e5874c3240a555b6f1ed34d4dd1b77d0"
   },
   "outputs": [],
   "source": [
    "print('Mean predict proba of churn:',round(output_df[output_df['churn'] == 1]['prediction'].mean(),2))\n",
    "print('Mean predict proba of NON-churn:',round(output_df[output_df['churn'] == 0]['prediction'].mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa312cf4a7453549cd923eb14b6b9f811394e7ec"
   },
   "source": [
    "Use this next dataframe for activation. Using media, let's target the customers who haven't churned but are likely to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "517f9c6c5a9870ba90174ed9607d05475c966877"
   },
   "outputs": [],
   "source": [
    "activate = output_df[output_df['churn'] == 0]\n",
    "activate[['customerID','churn','prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "26ee1b04bac13c038bad5f590f111def1a9a26a1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
